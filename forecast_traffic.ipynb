{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from dataset import *\n",
    "import gc\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        # System configs\n",
    "        self.gpu = 3\n",
    "        self.run_label = 0\n",
    "        self.verbose = False\n",
    "        self.log_root = '/data/hdim-forecast/log5/forecast'\n",
    "        \n",
    "        # Global model choice parameters\n",
    "        self.x_dim = 2         # Number of input features \n",
    "        self.y_dim = 131       # Number of predicted values\n",
    "        self.n_past = 32       # Number of steps from the past to condition on\n",
    "        self.n_future = 10     # Number of steps into the future to predict\n",
    "        self.feat_size = 131   # Number of basis features\n",
    "        self.lstm_hidden_dim = 256  \n",
    "        self.lstm_layers = 2\n",
    "        self.lstm_dropout = 0.5\n",
    "        self.prediction_model = 'lstm'        \n",
    "        \n",
    "        # Parameters only used for forecasting\n",
    "        self.f_learning_rate = 1e-2   # learning rate for optimizing queries\n",
    "        self.f_batch_size = 8    # batch size to evaluate each query on \n",
    "        self.n_sample = 1024   # Number of samples to simulate\n",
    "        \n",
    "        # Parameters only used for sampler training\n",
    "        self.s_test_len = 1024   # The length of test sequence to visualize\n",
    "        self.s_learning_rate = 1e-4  \n",
    "        self.s_batch_size = 8\n",
    "        \n",
    "        # Parameters only used for predictor training\n",
    "        self.p_learning_rate = 1e-4\n",
    "        self.p_batch_size = 32\n",
    "        \n",
    "args = Args()\n",
    "device = torch.device('cuda:%d' % args.gpu)\n",
    "args.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    args.name = '%s-%d-%d-%d-%d-%d-%d-%d-%.1f-%.4f-%d' % \\\n",
    "        (args.prediction_model, args.x_dim, args.y_dim, args.n_past, args.n_future, args.feat_size, \n",
    "         args.lstm_layers, args.lstm_hidden_dim, args.lstm_dropout, args.f_learning_rate, args.run_label)\n",
    "    args.log_dir = os.path.join(args.log_root, args.name)\n",
    "    if not os.path.isdir(args.log_dir):\n",
    "        os.makedirs(args.log_dir)\n",
    "        break\n",
    "    args.run_label += 1\n",
    "print(\"Run number = %d\" % args.run_label)\n",
    "writer = SummaryWriter(args.log_dir)\n",
    "log_writer = open(os.path.join(args.log_dir, 'results.txt'), 'w')\n",
    "\n",
    "start_time = time.time()\n",
    "global_iteration = 0\n",
    "random.seed(args.run_label)  # Set a different random seed for different run labels\n",
    "torch.manual_seed(args.run_label)\n",
    "    \n",
    "def log_scalar(name, value, epoch):\n",
    "    writer.add_scalar(name, value, epoch)\n",
    "    log_writer.write('%f ' % value)\n",
    "    \n",
    "def message(epoch):\n",
    "    print(\"Finished epoch %d, time elapsed %.1f\" % (epoch, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrafficDataset(train=True, max_len=args.n_past+args.n_future)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.f_batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = TrafficDataset(train=False, max_len=args.n_past+args.n_future)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.f_batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_model = FeatureNetFirstMoment(args.feat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.sample_name = '%s-%d-%d-%d-%d-%d-%d-%d-%.1f-%.4f-4' % \\\n",
    "        (args.prediction_model, args.x_dim, args.y_dim, args.n_past, args.n_future, args.feat_size, \n",
    "         args.lstm_layers, args.lstm_hidden_dim, args.lstm_dropout, args.s_learning_rate)\n",
    "    \n",
    "sampler = LSTMSampler(args)\n",
    "sampler.load_state_dict(torch.load('pretrained/sampler_traffic_%s.pt' % args.sample_name))\n",
    "sampler = sampler.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.predictor_name = '%s-%d-%d-%d-%d-%d-%d-%d-%.1f-%.4f-2' % \\\n",
    "        (args.prediction_model, args.x_dim, args.y_dim, args.n_past, args.n_future, args.feat_size, \n",
    "         args.lstm_layers, args.lstm_hidden_dim, args.lstm_dropout, args.p_learning_rate)\n",
    "predictor = PredictorRecurrent(args)\n",
    "predictor.load_state_dict(torch.load('pretrained/predictor_traffic_%s.pt' % args.predictor_name))\n",
    "predictor = predictor.eval().to(device)\n",
    "#             x: ([batch_size, n_past, x_dim]), the input feature\n",
    " #            y: ([batch_size, n_past, y_dim]), the previous step label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design a set of query functions, each query function should be a map from [batch_size, 1, 64, 64] tensor into a real number\n",
    "\n",
    "def get_query_travel():\n",
    "    num_route = torch.randint(low=3, high=10, size=(1,))\n",
    "    routes = torch.randperm(args.y_dim, device=args.device)[:num_route]\n",
    "    def query_func(y):   # Each query_func take as input y of size [batch_size, y_dim]\n",
    "        return y[:, routes].sum(dim=1)\n",
    "    return query_func\n",
    "\n",
    "def get_query_travel_sqr():\n",
    "    num_route = torch.randint(low=3, high=10, size=(1,))\n",
    "    routes = torch.randperm(args.y_dim, device=args.device)[:num_route]\n",
    "    def query_func(y):   # Each query_func take as input y of size [batch_size, y_dim]\n",
    "        return y[:, routes].sum(dim=1).pow(2)\n",
    "    return query_func\n",
    "\n",
    "def get_query_travel_thresh():\n",
    "    num_route = torch.randint(low=3, high=10, size=(1,))\n",
    "    routes = torch.randperm(args.y_dim, device=args.device)[:num_route]\n",
    "    def query_func(y):   # Each query_func take as input y of size [batch_size, y_dim]\n",
    "        return (y[:, routes].sum(dim=1) > 9).type(torch.float32)\n",
    "    return query_func\n",
    "\n",
    "\n",
    "queries_all = [get_query_travel_thresh() for i in range(10)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx, by = iter(test_loader).next()\n",
    "bx, by = bx.to(device).permute(1, 0, 2), by.to(device).permute(1, 0, 2)\n",
    "with torch.no_grad():\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    # bx_expanded = torch.cat([bx[0, :32], next_time(bx[0, -1, 1], 500)])\n",
    "    for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        samples = sampler.sample(bx, by[:args.n_past], args.n_future).permute(1, 0, 2)\n",
    "        plt.plot(torch.cat([by[0, :, 0], samples[0, :, 0]]).cpu())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor(bx[:, :args.n_past], by[:, :args.n_past]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_size = 16\n",
    "assert args.n_sample % mb_size == 0\n",
    "err_sim = []\n",
    "err_combo = []\n",
    "err_feat = []\n",
    "\n",
    "arr_sim, arr_pred, arr_pred_true, arr_residue, arr_residue_true, arr_exp_true = [], [], [], [], [], []\n",
    "\n",
    "for idx, data in enumerate(test_loader):\n",
    "    bx, by = data[0].to(device), data[1].to(device)\n",
    "\n",
    "    # print(bx.shape)\n",
    "    with torch.no_grad():\n",
    "        # Run the simulation over multiple batches to avoid memory overflow\n",
    "        sim_bx = torch.zeros(args.n_sample, args.f_batch_size, args.y_dim).to(device)\n",
    "        sim_feat = torch.zeros(args.n_sample, args.f_batch_size, args.feat_size).to(device)\n",
    "        \n",
    "        input_raw = by[:, -1, :].clone()\n",
    "        input_raw[input_raw <= 0.1] = float('nan')\n",
    "        true_feat = feat_model(input_raw)\n",
    "        for rep in range(args.n_sample):\n",
    "            by_in = by[:, :args.n_past, :].to(device)\n",
    "            # print(by_in.shape)\n",
    "            # print(bx_in.shape)\n",
    "            sim_bx[rep] = sampler.sample(bx.permute(1, 0, 2), by_in.permute(1, 0, 2), args.n_future)[-1]\n",
    "            # print(sim_bx.shape)\n",
    "            # print(simulated_bx.shape)\n",
    "        for rep in range(args.n_sample // mb_size):\n",
    "            sim_feat[rep*mb_size:(rep+1)*mb_size] = feat_model(sim_bx[rep*mb_size:(rep+1)*mb_size].view(-1, args.y_dim)).view(mb_size, args.f_batch_size, args.feat_size)\n",
    "\n",
    "    for q_index, query in enumerate(queries_all):\n",
    "        alpha = torch.randn([1, args.f_batch_size, args.feat_size], requires_grad=True, device=device)\n",
    "        alpha_optim = optim.Adam([alpha], lr=args.f_learning_rate)\n",
    "\n",
    "        sim_val = query(sim_bx.reshape(-1, args.y_dim)).view(args.n_sample, args.f_batch_size)\n",
    "        # print(sim_val)\n",
    "        for qiter in range(5000):\n",
    "            alpha_optim.zero_grad()\n",
    "            loss_q = (sim_val - (sim_feat * alpha).mean(dim=2)).abs().mean()\n",
    "            # print(loss_q, alpha)\n",
    "            # print(query(bx[:, 10]))\n",
    "            # print((feat_model(bx[:, 10]) * alpha).mean(dim=1))\n",
    "            loss_q.backward()\n",
    "            alpha_optim.step()\n",
    "            writer.add_scalar('loss_q_%d' % q_index, loss_q, qiter)\n",
    "        \n",
    "        # Compute the expectation if we were to use the simulated data only\n",
    "        with torch.no_grad():\n",
    "            true_exp = query(input_raw)\n",
    "            # print(true_exp)\n",
    "            valid_idx = ~torch.isnan(true_exp)\n",
    "            true_exp = true_exp[valid_idx]\n",
    "            if valid_idx.sum() == 0:\n",
    "                continue\n",
    "            # Expectation according to future simulations\n",
    "            sim_exp = sim_val.mean(dim=0)[valid_idx]\n",
    "            \n",
    "            # print(sim_exp)\n",
    "            # print(sim_exp.shape)\n",
    "            # Expectation of the features\n",
    "            # print(predictor(bx[0, :, 0:2]).shape)\n",
    "            pred_exp_feat = (predictor(bx[:, :args.n_past], by[:, :args.n_past]) * alpha[0]).mean(dim=1)[valid_idx]\n",
    "            # print(pred_exp_feat)\n",
    "            residue_exp = (sim_val - (sim_feat * alpha).mean(dim=2)).mean(dim=0)[valid_idx]\n",
    "            combo_exp = pred_exp_feat + residue_exp\n",
    "\n",
    "\n",
    "            \n",
    "            true_exp_feat = (true_feat.mean(dim=0) * alpha[0]).mean(dim=1)[valid_idx]\n",
    "            true_exp_residue = true_exp - true_exp_feat \n",
    "            \n",
    "            err_sim.append(sim_exp - true_exp)\n",
    "            err_combo.append(combo_exp - true_exp)\n",
    "            err_feat.append(pred_exp_feat - true_exp_feat)\n",
    "            \n",
    "            arr_residue.append(residue_exp)\n",
    "            arr_pred.append(pred_exp_feat)\n",
    "            arr_sim.append(sim_exp)\n",
    "            arr_pred_true.append(true_exp_feat)\n",
    "            arr_residue_true.append(true_exp_residue)\n",
    "            arr_exp_true.append(true_exp)\n",
    "    message(idx)\n",
    "    global_iteration += 1\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(true_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_sim = torch.cat(err_sim).cpu().numpy()\n",
    "err_combo = torch.cat(err_combo).cpu().numpy()\n",
    "err_feat = torch.cat(err_feat).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_residue = torch.cat(arr_residue).cpu().numpy()\n",
    "arr_pred = torch.cat(arr_pred).cpu().numpy()\n",
    "arr_pred_true = torch.cat(arr_pred_true).cpu().numpy()\n",
    "arr_sim = torch.cat(arr_sim).cpu().numpy()\n",
    "arr_residue_true = torch.cat(arr_residue_true).cpu().numpy()\n",
    "arr_exp_true = torch.cat(arr_exp_true).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_combo_clipped = (arr_pred + arr_residue).clip(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35050574 0.38502246\n",
      "0.4280135 0.46620408\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(np.square(err_sim)), np.mean(np.square(arr_combo_clipped - arr_exp_true)))\n",
    "print(np.mean(np.abs(err_sim)), np.mean(np.abs(err_combo)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_combo_alt = (arr_residue_true - arr_residue) + (arr_pred_true - arr_pred) \n",
    "err_pred = (arr_pred_true + arr_residue_true) - arr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.xlim([-100, 100])\n",
    "plt.hist(err_sim, bins=20, alpha=0.5, color='b', label='simulated')\n",
    "plt.hist(arr_combo_clipped - arr_exp_true, bins=20, alpha=0.5, color='r', label='combo')\n",
    "# plt.hist(err_feat, bins=40, color='g', alpha=0.5, label='pred')\n",
    "# plt.hist(err_combo_alt, bins=40, alpha=0.5, color='g', label='')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(arr_residue.cpu().numpy(), bins=20, alpha=0.5)\n",
    "plt.hist(arr_pred, bins=40, alpha=0.5, color='r')\n",
    "# plt.hist(arr_pred_true, bins=40, alpha=0.5, color='g')\n",
    "# plt.hist(arr_pred - arr_pred_true, bins=40, alpha=0.5, color='b')\n",
    "plt.hist(arr_residue, bins=40, alpha=0.5, color='m')\n",
    "# plt.hist(arr_exp_true, bins=40, alpha=0.5, color='c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
