{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from dataset import *\n",
    "from model import *\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.gpu = 3\n",
    "        self.run_label = 0\n",
    "        self.batch_size = 8\n",
    "        self.learning_rate = 1e-4\n",
    "        self.n_sample = 256\n",
    "        self.n_future = 10\n",
    "        self.n_past = 32\n",
    "        self.x_dim = 2\n",
    "        self.y_dim = 131\n",
    "        self.feat_size = 131\n",
    "        self.lstm_hidden_dim = 256\n",
    "        self.lstm_layers = 2\n",
    "        self.verbose = False\n",
    "        \n",
    "args = Args()\n",
    "device = torch.device('cuda:%d' % args.gpu)\n",
    "args.device = device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run number = 0\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    args.log_dir = '/data/hdim-forecast/log4/pred/seq=%d/%d-ns=%d-feat_size=%d-bs=%d-lr=%.5f-run=%d' % \\\n",
    "        (args.n_past, args.n_future, args.n_sample, args.feat_size, \n",
    "         args.batch_size, args.learning_rate, args.run_label)\n",
    "    if not os.path.isdir(args.log_dir):\n",
    "        os.makedirs(args.log_dir)\n",
    "        break\n",
    "    args.run_label += 1\n",
    "print(\"Run number = %d\" % args.run_label)\n",
    "writer = SummaryWriter(args.log_dir)\n",
    "log_writer = open(os.path.join(args.log_dir, 'results.txt'), 'w')\n",
    "\n",
    "start_time = time.time()\n",
    "global_iteration = 0\n",
    "random.seed(args.run_label)  # Set a different random seed for different run labels\n",
    "torch.manual_seed(args.run_label)\n",
    "    \n",
    "def log_scalar(name, value, epoch):\n",
    "    writer.add_scalar(name, value, epoch)\n",
    "    log_writer.write('%f ' % value)\n",
    "    \n",
    "def message(epoch):\n",
    "    print(\"Finished epoch %d, time elapsed %.1f\" % (epoch, time.time() - start_time))\n",
    "    \n",
    "def maybe_print(str_to_print):\n",
    "    if self.verbose:\n",
    "        print(str_to_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrafficDataset(train=True, max_len=args.n_past+args.n_future)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureNetMoment(nn.Module):\n",
    "    def __init__(self, x_dim):\n",
    "        super(FeatureNetMoment, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        first_order = x \n",
    "        return first_order\n",
    "        # second_order = x.unsqueeze(-1).repeat(1, 1, x.shape[1]) * x.unsqueeze(-2).repeat(1, x.shape[1], 1)\n",
    "        # ind = torch.triu_indices(x.shape[1], x.shape[1]) \n",
    "        # second_order = torch.stack([second_order[i][ind[0], ind[1]] for i in range(x.shape[0])])\n",
    "        # return torch.cat([first_order, second_order.view(x.shape[0], -1)], dim=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_model = FeatureNetMoment(args.feat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.2000],\n",
       "        [0.3000, 0.5000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_model(torch.tensor([[0.1, 0.2], [0.3, 0.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Defines the neural network, loss function and metrics'''\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class PredictorRecurrent(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        '''\n",
    "        We define a recurrent network that predicts the future values of a time-dependent variable based on\n",
    "        past inputs and covariates.\n",
    "        '''\n",
    "        super(PredictorRecurrent, self).__init__()\n",
    "        self.params = params\n",
    "        self.lstm = nn.LSTM(input_size=params.x_dim+params.y_dim,\n",
    "                            hidden_size=params.lstm_hidden_dim,\n",
    "                            num_layers=params.lstm_layers,\n",
    "                            bias=True,\n",
    "                            batch_first=False)\n",
    "        \n",
    "        # initialize LSTM forget gate bias to be 1 as recommanded by http://proceedings.mlr.press/v37/jozefowicz15.pdf\n",
    "        for names in self.lstm._all_weights:\n",
    "            for name in filter(lambda n: \"bias\" in n, names):\n",
    "                bias = getattr(self.lstm, name)\n",
    "                n = bias.size(0)\n",
    "                start, end = n // 4, n // 2\n",
    "                bias.data[start:end].fill_(1.)\n",
    "\n",
    "        self.fc1 = nn.Linear(params.lstm_hidden_dim * params.lstm_layers, 1024)\n",
    "        self.fc2 = nn.Linear(1024, params.feat_size)\n",
    "        \n",
    "\n",
    "    def forward(self, x, y_prev):\n",
    "        '''\n",
    "        Predict mu and sigma of the distribution for z_t.\n",
    "        Args:\n",
    "            x: ([batch_size, n_past+1, x_dim]), the input feature\n",
    "            y: ([batch_size, n_past, y_dim]), the previous step label\n",
    "        Returns:\n",
    "            pred \n",
    "            mu ([batch_size, y_dim]): estimated mean of z_t\n",
    "            sigma ([batch_size, y_dim]): estimated standard deviation of z_t\n",
    "            hidden ([lstm_layers, batch_size, lstm_hidden_dim]): LSTM h from time step t\n",
    "            cell ([lstm_layers, batch_size, lstm_hidden_dim]): LSTM c from time step t\n",
    "        '''\n",
    "        hidden, cell = self.init_hidden(x.shape[0]), self.init_cell(x.shape[0])\n",
    "        \n",
    "        lstm_input = torch.cat([x, y_prev], dim=-1)\n",
    "        # print(lstm_input.shape)\n",
    "        output, (hidden, cell) = self.lstm(lstm_input.permute(1, 0, 2), (hidden, cell))\n",
    "        \n",
    "        # print(output.shape, hidden.shape, cell.shape)\n",
    "            \n",
    "        # use h from all three layers to calculate mu and sigma\n",
    "        hidden_permute = hidden.permute(1, 0, 2).contiguous().view(hidden.shape[1], -1) \n",
    "        # print(hidden_permute.shape)\n",
    "        fc = F.leaky_relu(self.fc1(hidden_permute))\n",
    "        return self.fc2(fc)\n",
    "\n",
    "    def init_hidden(self, input_size):\n",
    "        return torch.zeros(self.params.lstm_layers, input_size, self.params.lstm_hidden_dim, device=self.params.device)\n",
    "\n",
    "    def init_cell(self, input_size):\n",
    "        return torch.zeros(self.params.lstm_layers, input_size, self.params.lstm_hidden_dim, device=self.params.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PredictorRecurrent(args).to(device)\n",
    "exp_optim = optim.Adam(predictor.parameters(), lr=args.learning_rate)\n",
    "scheduler = optim.lr_scheduler.StepLR(exp_optim, 20, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def next_time(week, num_steps):\n",
    "    start_time = week.item() * 3600 * 24 * 7\n",
    "    time_new = torch.linspace(start_time, start_time + 5*60*(num_steps-1), num_steps, device=week.device)\n",
    "    hour_of_day = (time_new % (3600 * 24)) / (3600. * 24)\n",
    "    week_day = (time_new % (3600 * 24 * 7)) / (3600 * 24. * 7)\n",
    "    return torch.stack([hour_of_day, week_day], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 42, 2]) torch.Size([8, 42, 131])\n"
     ]
    }
   ],
   "source": [
    "bx, by = iter(train_loader).next()\n",
    "print(bx.shape, by.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-b5f2a1af8748>\", line 4, in <module>\n",
      "    exp_optim.zero_grad()\n",
      "NameError: name 'exp_optim' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'NameError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/home/zsj/.local/lib/python3.6/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"/home/zsj/.local/lib/python3.6/site-packages/tensorflow/__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"/usr/lib/python3.6/importlib/__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/zsj/.local/lib/python3.6/site-packages/tensorflow_core/contrib/__init__.py\", line 48, in <module>\n",
      "    from tensorflow.contrib import estimator\n",
      "  File \"/home/zsj/.local/lib/python3.6/site-packages/tensorflow_core/contrib/estimator/__init__.py\", line 30, in <module>\n",
      "    from tensorflow_estimator.contrib import estimator\n",
      "ModuleNotFoundError: No module named 'tensorflow_estimator.contrib'\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exp_optim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Learn the conditional expectation\n",
    "for epoch in range(2000):\n",
    "    for idx, data in enumerate(train_loader):\n",
    "        exp_optim.zero_grad()\n",
    "\n",
    "        bx, by = data[0].to(device), data[1].to(device)\n",
    "        # by has shape [batch_size, seq_len, num_streets]\n",
    "        actual_feat = feat_model(by[:, -1, :]).detach()\n",
    "        # print(bx.shape, by.shape)\n",
    "        pred_exp = predictor(bx[:, :args.n_past], by[:, :args.n_past])\n",
    "        \n",
    "        loss_l2 = (actual_feat - pred_exp).pow(2).mean()\n",
    "        loss_l2.backward()\n",
    "\n",
    "        writer.add_scalar('loss_l2', loss_l2, global_iteration)\n",
    "        exp_optim.step()\n",
    "        global_iteration += 1\n",
    "            \n",
    "    scheduler.step()\n",
    "    message(epoch)\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(predictor.state_dict(), 'pretrained/predictor_traffic_%d-%d-%s.pt' % (args.feat_size, args.n_future, args.predictor_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(actual_feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
